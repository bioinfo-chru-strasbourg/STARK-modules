##########################################################################
# Config Yaml Version:     1.0
# Description:             Yaml file to run DECON Snakefile module
##########################################################################
# DEV version 0.1 : 10/11/2021
# INT version 0.1 : 17/03/2022
# PROD version 1 : 03/06/2022
# Authoring : Thomas LAVAUX
# PROD version 2 : 16/06/2022 changelog
# add the possibility to analyse gender separately, extract gender from tag files ; gender analysis can be set with REMOVE_F & REMOVE_M & REMOVE_A options
# add a gene list restriction to limit the analysis to a certain list of gene's name (GENE_FILTER & GENE_LIST_RESTRICT)
# add a chr filter option to remove chrosome (essentially chrY) CHR_FILTER & CHR_LIST_RESTRICT)
##########################################################################
# Add here variables that will extend default configuration yaml file.
# If a variable was already defined in the default configuration yaml file, it will be replace.
# launch snakemake -s decon.smk -c(numberofthreads) --config run=absolutepathoftherundirectory var1=0.05 var2=12
# separate multiple variable with a space
################## Directories and variables ##################

# Name of the submodule = {serviceName} from listener.py/launcher.py
serviceName: "DECON"
# Name of the module
moduleName: "structuralvariation"
# Databases folder
databases: "/databases"
# Service folder
services: "/services"
# Config folder
config: "/config"
# Specify a DATE_TIME value (for rerun)
DATE_TIME: ""
# Output directory
OUTPUT_DIR: ""
# Other path to copy results, leave empty to not copy, add a path to copy to this folder
# Replace by "depository" will copy the results in a second folder based on OUTPUT_DIR, replacing "repository" with "depository" if repository exist
DEPOT_DIR: "depository"
# Default path to the input datas == {run} from listener.py/launcher.py
run: ""

# Bed file
BED_FILE: ""
# Genes file
GENES_FILE: ""
# Transcripts file
TRANSCRIPTS_FILE: ""
# List genes
LIST_GENES: ""

# Samples list exclusion (not to be analyse) ; exclude if startwith, case insensitive
EXCLUDE_SAMPLE: ['POOL_', 'BlcADN', 'blanc', 'BlcPCR', 'blcPCR', 'Z_NTC', 'NTC', 'Blc']
# Sample filter : only analyse those samples
FILTER_SAMPLE: []

# Files to index into the dictionary depending on extension (endwith)
EXT_INDEX_LIST: [".cram", ".cram.crai", ".transcripts", ".genes.bed", ".design.bed", ".bam", ".bam.bai", ".list.genes", ".tag", ".ped", ".final.vcf.gz"]
# List of files extension to process
PROCESS_FILE: ['.bam', 'bam.bai']
# How to copy input files (bam, bai, cram) : ln or leave empty (it will rsync files or index for bai from bam)
PROCESS_CMD: 'ln'
# Append an aligner name if no empty (from sample.bam to sample.alignername.bam)
ALIGNER_NAME:
# Only analyse sample.validation.aligner.bam/cram files
VALIDATION_ONLY: False

# Extension files to copy after pipeline success
# using brace extension, remove space between extensions
INCLUDE_RSYNC: "{'*Design.vcf.gz','*Design.vcf.gz.tbi','*AnnotSV.Design.tsv','*allsamples.Design.tsv','*Panel*.vcf.gz','*Panel*.vcf.gz.tbi','*Panel*.tsv','*Metrics.tsv','*.pdf','*.html','*.css','*/'}"
# Extensions files to copy after pipeline failure
INCLUDE_LOG_RSYNC: "{'*.log','*.err','*Failed.txt','*.bed','*/'}"

##### Search parameters of input for the search function #####
RECURSIVE_SEARCH: False
SEARCH_ARGUMENT: ["/*/STARK/*", "/*/*"]

# LOG level 30=logging.WARNING or 20=logging.INFO
LOG_LEVEL: 30

# Path of the template foldre (template is serviceName_template.html)
TEMPLATE_DIR: "/app/template"
# List of extensions to include in the report.html
RESULT_EXT_LIST: ['.vcf.gz', '.vcf.gz.tbi', 'merge.pdf', 'Design.tsv', 'Metrics.tsv']

############## Tools specific parameters ##############
### TOOLS PATH ###
# Default path to a FASTA file with .fasta reference genome (hg19/hg38 for ex)
REFGENEFA_PATH: "/databases/genomes/current/hg19.fa"
# path to Refgene file containing custom exon numbers  
# http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/
# archive formated_refgene for hg19 avalaible in /app/database
REFSEQGENE_PATH: "/databases/refGene/current/formated_refgene.tsv"

### DECON BED processing ###
# Regen exon number with IntersectBed and a refseqgene reference (REGEN) containing a column with the exon number
# Else STANDARD (use the bed provided)
BED_PROCESS: "STANDARD"
# Keep intergenic region when exon regen is done
KEEP_UNKNOWN: False
# Remove separator in the DECON bed for gene name (TP53_ex for ex)
EXON_SEP: "_ex"
# Old Bed formating (True if bed got 4 columns only; False if bed got 13 columns with th 13th containing exon numbers)
OLD_BED: True

## Analysis processing ##
# Remove M or F or Autosome analysis, ex ['XY', 'XX'] for autosome only
REMOVE_GENDER: ""
# Limit the analysis to a list of genes (remove from DECON BED)
GENE_LIST_RESTRICT: []
# List of chr to remove from DECON BED
CHR_LIST_RESTRICT: []
# If bed file got a 5 column with exon number 
customexon: FALSE
# kmerisation of DECON bed (integer) (ex 250)
KMER: ""

# Path for scripts and dummy files folders
DUMMY_FILES: "/app/scripts/dummy"
R_SCRIPTS: "/app/scripts/R"
PY_SCRIPTS: "/app/scripts/python"
# Path of the fileconversion json folder
VARIANT_CONVERT_CONFIG: "/app/config/fileconversion"

### DECON ###
# Plots for DECON True/False
DECON_PLOT: True
############# ReadInbams params ##############
# path to the tsv file containing 2 columns : bam for the list of reference bams for CNV calling (full path of bams), and gender (F/M)
# the bam files have to be indexed
# number of reference patients should be 10 or more, and if the gender is considere, 10 per gender
# the panel of genes and the technology of sequencing (capture/amplicon) must be identical between reference samples and patient samples
# REF_BAM_LIST: "--refbams /app/res/list.tsv"
REF_BAM_LIST: ""
# Max cores to use
MCORES: 16

################## AnnotSV params for DB setup ##################
# don't forget to change application.properties from /app/config/annotsv
ANNOTSV_VERSION: "3.4"
EXOMISER_VERSION: "2402"
# Other params
ASSEMBLY: "hg19" # must be consistant with genomeBuild variable
# accessory db
# GeneHancer data is under a specific licence that prevent the systematic availability in AnnotSV sources. Users need to request the up-to-date GeneHancer data dedicated to AnnotSV " #(“GeneHancer_<version>_for_annotsv.zip“) by subscribing to the Genecard web site https://www.genecards.org/
# unzip -q GeneHancer_<version>_for_annotsv.zip -d ($ANNOTSV/share/AnnotSV)/Annotations_Human/FtIncludedInSV/RegulatoryElements/
GENEHANCER_VERSION: "GeneHancer_hg19_v5.9"
# Cosmic db is CosmicCompleteCNA.tsv.gz

# HTTPS links for AnnotSV and Exomiser downloads
ANNOTSV_DOWNLOAD_LINK: "https://www.lbgi.fr/~geoffroy/Annotations/Annotations_Human_{ANNOTSV_VERSION}.tar.gz"
EXOMISER_DOWNLOAD_LINK1: "https://data.monarchinitiative.org/exomiser/data/{EXOMISER_VERSION}_{assembly}.zip"
EXOMISER_DOWNLOAD_LINK2: "https://data.monarchinitiative.org/exomiser/data/{EXOMISER_VERSION}_phenotype.zip"

# Command to download
COMMAND: "aria2c --async-dns=false -c -s 16 -x 16 -k 1M -j 1"

############# IdentifyFailures params ##############
mincorr: 0.98 # Minimum correlation threshold – the minimum correlation between a test sample and any other sample for the test sample to be considered well-correlated (default 0.98)
mincov: 100 # Minimum coverage threshold – the minimum median coverage for any sample (measured across all exons in the target) or exon (measured across all samples) to be considered well-covered (default 100)

############# makeCNVcalls params ##############
transProb: 0.01 # Transition probability – the transition probability between normal copy number state and either deletion or duplication state in the hidden Markov model, 0.01 is a high threshold value to increase sensitivity (default 0.01)
############# AnnotSV params ##############
genomeBuild: GRCh37 # GRCh38 default, set to GRCh37 for hg19
overlap: 100 # default 100
annotationMode: full # split, full or both (defaut both)
annotationdir: "/databases/AnnotSV/3.4/" # path to the annotation database
vcf_extension: ".final.vcf.gz" # vcf extension to annotate with the -snvIndelFiles option ; extension should be in EXT_INDEX_LIST

# AnnotSV needs the "CosmicCompleteCNA.tsv.gz" file from https://cancer.sanger.ac.uk/cosmic/download (Copy Number Variants part, Download Whole file)
# Put the "CosmicCompleteCNA.tsv.gz" file in the corresponding directory: "$ANNOTSV/share/AnnotSV/Annotations_Human/FtIncludedInSV/COSMIC/GRCh37/
# create the directory is necessary (./Annotations_Human/FtIncludedInSV/COSMIC/GRCh37/)
# These files will be reprocessed and then removed the first time AnnotSV is executed.

## Auto install COSMIC Annotation for SV
# 1 - Generate an authentication string
# Your first request needs to supply your registered email address and COSMIC password. 
# We use HTTP Basic Auth to check your credentials, which requires you to combine your email address and password and then Base64 encode them. 
# For example, using standard Unix command line tools: 
# echo "email@example.com:mycosmicpassword" | base64
# yougetthekey64
# You can use the same authentication string for all of your downloads. You only need to re-generate the string if you change your COSMIC password. 

# 2 - Get a download link
#Make a request to https://cancer.sanger.ac.uk/cosmic/file_download/GRCh37/cosmic/v95/CosmicCompleteCNA.tsv.gz. 
# You need to pass the authentication string to the server when you make your request. For example: 
# curl -H "Authorization: Basic yougetthekey64" https://cancer.sanger.ac.uk/cosmic/file_download/GRCh37/cosmic/v95/CosmicCompleteCNA.tsv.gz
# That request will return a snippet of JSON containing the link that you need to use to download your file. For example: 
#{"url" : "https://cog.sanger.ac.uk/cosmic/GRCh37/cosmic/v95/CosmicCompleteCNA.tsv.gz?AWSAccessKeyId=yourID&Expires=yourData" }

# 3 - Download the data file
# Extract the URL from the JSON response and make another request to that URL to download the file. For example:
# curl "https://cog.sanger.ac.uk/cosmic/GRCh37/cosmic/v95/CosmicCompleteCNA.tsv.gz?AWSAccessKeyId=yourID&Expires=yourData"
# You do not need to supply the authentication header on this request. Download links are valid for one hour. 