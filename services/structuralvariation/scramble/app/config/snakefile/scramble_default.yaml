##########################################################################
# Config Yaml Version:     0.1
# Description:             Yaml file to run Snakefile SCRAMBLE module
##########################################################################
# DEV version 0.1 : 10/11/2021
# INT version 0.1 : 17/03/2022
# PROD version 1 : 03/06/2022
# Authoring : Thomas LAVAUX
# Add here variables that will extend default configuration yaml file.
# If a variable was already defined in the default configuration yaml file, it will be replace.
# launch snakemake -s decon.smk -c(numberofthreads) --config run=absolutepathoftherundirectory var1=0.05 var2=12
# separate multiple variable with a space
################## Directories and variables ##################

# Name of the submodule = {serviceName} from listener.py/launcher.py
serviceName: "SCRAMBLE"
# Name of the module
moduleName: "structuralvariation"
# Databases folder
databases: "/databases"
# Service folder
services: "/services"
# Config folder
config: "/config"

# Specify a DATE_TIME value (for rerun)
DATE_TIME: ""
# Output directory
OUTPUT_DIR: ""
# Other path to copy results, leave empty to not copy, add a path to copy to this folder
# Replace by "depository" will copy the results in a second folder based on OUTPUT_DIR, replacing "repository" with "depository" if repository exist
DEPOT_DIR: "depository"
# Default path to the input datas == {run} from listener.py/launcher.py
run: ""

# Bed file
BED_FILE: ""
# Genes file
GENES_FILE: ""
# Transcripts file
TRANSCRIPTS_FILE: ""
# List genes
LIST_GENES: ""

# Samples list exclusion (not to be analyse) ; exclude if startwith, case insensitive
EXCLUDE_SAMPLE: ['POOL_', 'BlcADN', 'blanc', 'BlcPCR', 'blcPCR', 'Z_NTC', 'NTC', 'Blc']
# Sample filter, only those samples will be analysed
FILTER_SAMPLE: []

# Files to index into the dictionary depending on extension (endwith)
EXT_INDEX_LIST: [".cram", ".cram.crai", ".transcripts", ".genes.bed", ".design.bed", ".bam", ".bam.bai", ".list.genes", ".tag", ".ped", ".final.vcf.gz"]
# List of files extension to process
PROCESS_FILE: ['.bam', 'bam.bai']
# How to copy input files (bam, bai, cram) : ln or leave empty (it will rsync files & index bam)
PROCESS_CMD: 'ln'
# Append an aligner name if no empty (from sample.bam to sample.alignername.bam)
ALIGNER_NAME:
# Only analyse sample.validation.aligner.bam/cram files
VALIDATION_ONLY: False

# Extension files to copy after pipeline success
# using brace extension, remove space between extensions
INCLUDE_RSYNC: "{'*Full.vcf.gz','*Full.vcf.gz.tbi','*Design.vcf.gz','*Design.vcf.gz.tbi','*AnnotSV.Full.tsv','*AnnotSV.Design.tsv','*Panel*.vcf.gz','*Panel*.vcf.gz.tbi','*Panel*.tsv','*.html','*.css','*/'}"
# Extensions files to copy after pipeline failure
INCLUDE_LOG_RSYNC: "{'*.log','*.err','*Failed.txt'}"

##### Search parameters for inputs ####
RECURSIVE_SEARCH: False
SEARCH_ARGUMENT: ["/*/STARK/*", "/*/*"]

# LOG level 30=logging.WARNING or 20=logging.INFO
LOG_LEVEL: 30

# Path of the template (template is serviceName_template.html)
TEMPLATE_DIR: "/app/template"
# List of extensions to include in the report.html
RESULT_EXT_LIST: ['.vcf.gz', '.vcf.gz.tbi', "gender", "hpo"]


# Option to filter vcf with bcftools
# ex "-i 'FORMAT/DP>=30 && FORMAT/VAF>=0.01'" or "-e 'ABS(SVLEN) >= 10000'" -e exclude -i include 
BCFTOOLS_FILTER: "-e 'ABS(SVLEN) >= 100000'"
################## Tools specific parameters ##################
# Default path to a FASTA file with .fasta reference genome (hg19/hg38 for ex)
REFGENEFA_PATH: "/databases/genomes/current/hg19.fa"

# Path for scripts and dummy files
DUMMY_FILES: "/app/scripts/dummy"
R_SCRIPTS: "/app/scripts/R"

# Scripts py
SPLIT_SCRIPT: "/app/scripts/python/split_tsv.py"
MULTIFIX_SCRIPT: "/app/scripts/python/multifix_vcf.py"
MERGE_SCRIPT: "/app/scripts/python/merge_tsv.py"

# Fileconversion json for variantconvert
VARIANT_CONVERT_ANNOTSV: "/app/config/fileconversion/annotsv3_from_vcf.json"

# Path to Scramble R directory scripts
SCRAMBLE_PATH: "/opt/conda/share/scramble/bin" # installed via conda
################## cluster_identifier params
m: 10 # min soft clipped bases to be put in a cluster (default 10)
s: 5 # min soft clipped reads to be a cluster (default 5)
r: all # region (default all : format ex chr9:1-20000)

################## scramble params
nCluster: 5 # min cluster size to analyze (default 5)
mei-score: 50 # min MEI alignment score to call (default 50)
poly-a-frac: 0.75 # fraction of clipped length for calling polyA tail in MEIs (default 0.75)
poly-a-dist: 100 # how far from MEI to look for polyA tail (default 100)
# choose to evaluate meis (default) or deletions or both
# --eval-meis / --eval-dels / --eval-meis --eval-dels
scramble_mode: "--eval-meis"
# Default path to an FASTA file with MEI Ref sequences
REFMEI_PATH: "/opt/conda/share/scramble/resources/MEI_consensus_seqs.fa"

################## AnnotSV params for DB setup ##################
# don't forget to change application.properties from /app/config/annotsv
ANNOTSV_VERSION: "3.4"
EXOMISER_VERSION: "2402"
# Other params
ASSEMBLY: "hg19" # must be consistant with genomeBuild variable
# accessory db
# GeneHancer data is under a specific licence that prevent the systematic availability in AnnotSV sources. Users need to request the up-to-date GeneHancer data dedicated to AnnotSV " #(“GeneHancer_<version>_for_annotsv.zip“) by subscribing to the Genecard web site https://www.genecards.org/
# unzip -q GeneHancer_<version>_for_annotsv.zip -d ($ANNOTSV/share/AnnotSV)/Annotations_Human/FtIncludedInSV/RegulatoryElements/
GENEHANCER_VERSION: "GeneHancer_hg19_v5.9"
# Cosmic db is CosmicCompleteCNA.tsv.gz

# HTTPS links for AnnotSV and Exomiser downloads
ANNOTSV_DOWNLOAD_LINK: "https://www.lbgi.fr/~geoffroy/Annotations/Annotations_Human_{ANNOTSV_VERSION}.tar.gz"
EXOMISER_DOWNLOAD_LINK1: "https://data.monarchinitiative.org/exomiser/data/{EXOMISER_VERSION}_{assembly}.zip"
EXOMISER_DOWNLOAD_LINK2: "https://data.monarchinitiative.org/exomiser/data/{EXOMISER_VERSION}_phenotype.zip"

# Command to download
COMMAND: "aria2c --async-dns=false -c -s 16 -x 16 -k 1M -j 1"

################## AnnotSV params ##################
genomeBuild: GRCh37 # GRCh38 default, set to GRCh37 for hg19
overlap: 100 # default 100
annotationMode: full # split, full or both (defaut both)
annotationdir: "/databases/AnnotSV/3.4/" # path to the annotation database
vcf_extension: ".final.vcf.gz" # vcf extension to annotate with the -snvIndelFiles option ; extension should be in EXT_INDEX_LIST

# AnnotSV needs the "CosmicCompleteCNA.tsv.gz" file from https://cancer.sanger.ac.uk/cosmic/download (Copy Number Variants part, Download Whole file)
# Put the "CosmicCompleteCNA.tsv.gz" file in the corresponding directory: "$ANNOTSV/share/AnnotSV/Annotations_Human/FtIncludedInSV/COSMIC/GRCh37/
# create the directory is necessary (./Annotations_Human/FtIncludedInSV/COSMIC/GRCh37/)
# These files will be reprocessed and then removed the first time AnnotSV is executed.

## Auto install COSMIC Annotation for SV
# 1 - Generate an authentication string
# Your first request needs to supply your registered email address and COSMIC password. 
# We use HTTP Basic Auth to check your credentials, which requires you to combine your email address and password and then Base64 encode them. 
# For example, using standard Unix command line tools: 
# echo "email@example.com:mycosmicpassword" | base64
# yougetthekey64
# You can use the same authentication string for all of your downloads. You only need to re-generate the string if you change your COSMIC password. 

# 2 - Get a download link
#Make a request to https://cancer.sanger.ac.uk/cosmic/file_download/GRCh37/cosmic/v95/CosmicCompleteCNA.tsv.gz. 
# You need to pass the authentication string to the server when you make your request. For example: 
# curl -H "Authorization: Basic yougetthekey64" https://cancer.sanger.ac.uk/cosmic/file_download/GRCh37/cosmic/v95/CosmicCompleteCNA.tsv.gz
# That request will return a snippet of JSON containing the link that you need to use to download your file. For example: 
#{"url" : "https://cog.sanger.ac.uk/cosmic/GRCh37/cosmic/v95/CosmicCompleteCNA.tsv.gz?AWSAccessKeyId=yourID&Expires=yourData" }

# 3 - Download the data file
# Extract the URL from the JSON response and make another request to that URL to download the file. For example:
# curl "https://cog.sanger.ac.uk/cosmic/GRCh37/cosmic/v95/CosmicCompleteCNA.tsv.gz?AWSAccessKeyId=yourID&Expires=yourData"
# You do not need to supply the authentication header on this request. Download links are valid for one hour. 